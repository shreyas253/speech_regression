<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of gmmbvl_em_init_km</title>
  <meta name="keywords" content="gmmbvl_em_init_km">
  <meta name="description" content="gmmbvl_em_init_km - initialization of EM for Gaussian mixtures">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html &copy; 2003 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../index.html">Home</a> &gt;  <a href="index.html">gmmbayestb-v1.0</a> &gt; gmmbvl_em_init_km.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../index.html"><img alt="<" border="0" src="../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for gmmbayestb-v1.0&nbsp;<img alt=">" border="0" src="../right.png"></a></td></tr></table>-->

<h1>gmmbvl_em_init_km
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>gmmbvl_em_init_km - initialization of EM for Gaussian mixtures</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>function [W,M,R,P,sigma] = gmmbvl_em_init_km(X,k,dyn) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre class="comment">gmmbvl_em_init_km - initialization of EM for Gaussian mixtures 

[W,M,R,P,sigma] = gmmbvl_em_init_km(X,k,dyn)
  X - (n x d) matrix of input data 
  k - initial number of Gaussian components
  dyn - if 1 then perform dynamic component allocation else normal EM 
returns
  W - (k x 1) vector of mixing weights
  M - (k x d) matrix of components means
  R - (k x d^2) matrix of Cholesky submatrices of components covariances
  P - (n x k) the posteriors to be used in EM step after initialization
  of priors, means, and components covariance matrices</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="gmmbvl_em_gauss.html" class="code" title="function L = gmmbvl_em_gauss(X,M,R)">gmmbvl_em_gauss</a>	gmmbvl_em_gauss - compute likelihoods for all points and all components</li><li><a href="gmmbvl_kmeans.html" class="code" title="function [Er,M,nb] = gmmbvl_kmeans(X,T,kmax,dyn,bs, killing, pl)">gmmbvl_kmeans</a>	gmmbvl_kmeans - clustering with k-means (or Generalized Lloyd or LBG) algorithm</li><li><a href="gmmbvl_sqdist.html" class="code" title="function d = gmmbvl_sqdist(a,b)">gmmbvl_sqdist</a>	gmmbvl_sqdist - computes pairwise squared Euclidean distances between points</li></ul>
This function is called by:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="gmmbvl_em.html" class="code" title="function [W,M,R,varargout] = gmmbvl_em(X,kmax,nr_of_cand,plo,dia, logging)">gmmbvl_em</a>	gmmbvl_em - EM algorithm for adaptive multivariate Gaussian mixtures</li></ul>
<!-- crossreference -->


<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [W,M,R,P,sigma] = gmmbvl_em_init_km(X,k,dyn)</a>
0002 <span class="comment">%gmmbvl_em_init_km - initialization of EM for Gaussian mixtures</span>
0003 <span class="comment">%</span>
0004 <span class="comment">%[W,M,R,P,sigma] = gmmbvl_em_init_km(X,k,dyn)</span>
0005 <span class="comment">%  X - (n x d) matrix of input data</span>
0006 <span class="comment">%  k - initial number of Gaussian components</span>
0007 <span class="comment">%  dyn - if 1 then perform dynamic component allocation else normal EM</span>
0008 <span class="comment">%returns</span>
0009 <span class="comment">%  W - (k x 1) vector of mixing weights</span>
0010 <span class="comment">%  M - (k x d) matrix of components means</span>
0011 <span class="comment">%  R - (k x d^2) matrix of Cholesky submatrices of components covariances</span>
0012 <span class="comment">%  P - (n x k) the posteriors to be used in EM step after initialization</span>
0013 <span class="comment">%  of priors, means, and components covariance matrices</span>
0014 
0015 <span class="comment">% Nikos Vlassis &amp; Sjaak Verbeek 2002</span>
0016 
0017 <span class="comment">%</span>
0018 <span class="comment">% $Name:  $</span>
0019 
0020 [n,d] = size(X);
0021 
0022 [tmp,M,tmp2] = <a href="gmmbvl_kmeans.html" class="code" title="function [Er,M,nb] = gmmbvl_kmeans(X,T,kmax,dyn,bs, killing, pl)">gmmbvl_kmeans</a>(X,[],k,0,0,0,0);
0023 [D,I]        = min(<a href="gmmbvl_sqdist.html" class="code" title="function d = gmmbvl_sqdist(a,b)">gmmbvl_sqdist</a>(M',X'),[],1);
0024 
0025 <span class="comment">% mixing weights</span>
0026 W = zeros(k,1);
0027 <span class="keyword">for</span> i=1:k
0028     W(i) = length(find(I==i))/n;
0029 <span class="keyword">end</span>
0030 
0031 <span class="comment">% covariance matrices</span>
0032 R = zeros(k,d^2);
0033 <span class="keyword">if</span> k &gt; 1
0034     <span class="keyword">for</span> j = 1:k
0035         J = find(I==j);
0036         <span class="keyword">if</span> length(J)&gt;2*d;
0037             Sj = cov(X(J,:));
0038         <span class="keyword">else</span>
0039             Sj = cov(X);
0040         <span class="keyword">end</span>
0041         Rj = chol(Sj);
0042         R(j,:) = Rj(:)';
0043     <span class="keyword">end</span>
0044 <span class="keyword">else</span>
0045     S = cov(X);
0046     R = chol(S);
0047     R = R(:)';
0048 <span class="keyword">end</span>
0049 
0050 <span class="comment">% compute likelihoods L (n x k)</span>
0051 L = <a href="gmmbvl_em_gauss.html" class="code" title="function L = gmmbvl_em_gauss(X,M,R)">gmmbvl_em_gauss</a>(X,M,R);
0052 
0053 <span class="comment">% compute mixture likelihoods F (n x 1)</span>
0054 F = L * W;
0055 F(find(F &lt; eps)) = eps;
0056 
0057 <span class="comment">% compute posteriors P (n x k)</span>
0058 P = L .* repmat(W',n,1)  ./ repmat(F,1,k);
0059 
0060 sigma = 0.5 * (4/(d+2)/n)^(1/(d+4)) * sqrt(norm(cov(X)));</pre></div>
<hr><address>Generated on Thu 14-Apr-2005 13:50:22 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/">m2html</a></strong> &copy; 2003</address>
</body>
</html>